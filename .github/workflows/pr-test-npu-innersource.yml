name: PR Test For Innersource (Ascend NPU)

on:
  push:
    branches: [ main ]
    paths:
      - "python/**"
      - "scripts/**"
      - "test/**"
      - ".github/workflows/pr-test-npu-innersource.yml"
  pull_request:
    branches: [ main ]
    paths:
      - "python/**"
      - "scripts/**"
      - "test/**"
      - ".github/workflows/pr-test-npu-innersource.yml"
  workflow_dispatch:

concurrency:
  group: pr-test-npu-innersource-${{ github.ref }}
  cancel-in-progress: true

jobs:
  per-commit-1-ascend-npu:
    if: (github.repository == 'Ascend/sglang' || github.event_name == 'pull_request') &&
        github.event.pull_request.draft == false
    runs-on: linux-arm64-npu-1
    container:
      image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/cann:8.2.rc1-910b-ubuntu22.04-py3.11
    steps:
      - name: Pre-config git access token
        run: |
          # as we use a proxy but checkout@v4 only set basic auth header for github.com
          # so we set the extraheader manually
          TOKEN=`echo -n "x-access-token:${{ secrets.GITHUB_TOKEN}}"|base64`
          git config --global http.https://gh-proxy.test.osinfra.cn/.extraheader "AUTHORIZATION: basic $TOKEN"

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          # speed up by using infra cache services
          CACHING_URL="cache-service.nginx-pypi-cache.svc.cluster.local"
          sed -Ei "s@(ports|archive).ubuntu.com@${CACHING_URL}:8081@g" /etc/apt/sources.list
          pip config set global.index-url http://${CACHING_URL}/pypi/simple
          pip config set global.trusted-host ${CACHING_URL}

          bash scripts/ci/npu_ci_install_dependency.sh
          # copy required file from our daily cache
          cp ~/.cache/modelscope/hub/datasets/otavia/ShareGPT_Vicuna_unfiltered/ShareGPT_V3_unfiltered_cleaned_split.json /tmp
          # copy download through proxy
          curl -o /tmp/test.jsonl -L https://gh-proxy.test.osinfra.cn/https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/test.jsonl

      - name: Run test
        timeout-minutes: 120
        env:
          SGLANG_USE_MODELSCOPE: true
          SGLANG_IS_IN_CI: true
          HF_ENDPOINT: https://hf-mirror.com
          TORCH_EXTENSIONS_DIR: /tmp/torch_extensions
        run: |
          cd test/srt
          python3 run_suite.py --suite per-commit-1-ascend-npu

  per-commit-2-ascend-npu:
    if: (github.repository == 'Ascend/sglang' || github.event_name == 'pull_request') &&
        github.event.pull_request.draft == false
    runs-on: linux-arm64-npu-2
    container:
      image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/cann:8.2.rc1-910b-ubuntu22.04-py3.11
    steps:
      - name: Pre-config git access token
        run: |
          # as we use a proxy but checkout@v4 only set basic auth header for github.com
          # so we set the extraheader manually
          TOKEN=`echo -n "x-access-token:${{ secrets.GITHUB_TOKEN}}"|base64`
          git config --global http.https://gh-proxy.test.osinfra.cn/.extraheader "AUTHORIZATION: basic $TOKEN"

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          # speed up by using infra cache services
          CACHING_URL="cache-service.nginx-pypi-cache.svc.cluster.local"
          sed -Ei "s@(ports|archive).ubuntu.com@${CACHING_URL}:8081@g" /etc/apt/sources.list
          pip config set global.index-url http://${CACHING_URL}/pypi/simple
          pip config set global.trusted-host ${CACHING_URL}

          bash scripts/ci/npu_ci_install_dependency.sh
          # copy required file from our daily cache
          cp ~/.cache/modelscope/hub/datasets/otavia/ShareGPT_Vicuna_unfiltered/ShareGPT_V3_unfiltered_cleaned_split.json /tmp
          # copy download through proxy
          curl -o /tmp/test.jsonl -L https://gh-proxy.test.osinfra.cn/https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/test.jsonl

      - name: Run test
        timeout-minutes: 120
        env:
          SGLANG_USE_MODELSCOPE: true
          SGLANG_IS_IN_CI: true
          HF_ENDPOINT: https://hf-mirror.com
          TORCH_EXTENSIONS_DIR: /tmp/torch_extensions
        run: |
          cd test/srt
          python3 run_suite.py --suite per-commit-2-ascend-npu --timeout-per-file 7200

#  per-commit-ascend-npu-deepep:
#    if: (github.repository == 'sglang-npu/sglang_npu' || github.event_name == 'pull_request') &&
#        github.event.pull_request.draft == false
#    strategy:
#      matrix:
#        runner: [linux-aarch64-a3-node0, linux-aarch64-a3-node1, linux-aarch64-a3-node2, linux-aarch64-a3-node3]
#    runs-on: ${{matrix.runner}}
#    steps:
#      - name: Pre-config git access token
#        run: |
#          # as we use a proxy but checkout@v4 only set basic auth header for github.com
#          # so we set the extraheader manually
#          TOKEN=`echo -n "x-access-token:${{ secrets.GITHUB_TOKEN}}"|base64`
#          git config --global http.https://gh-proxy.test.osinfra.cn/.extraheader "AUTHORIZATION: basic $TOKEN"
#
#      - name: Clean workspace
#        run: |
#          sudo rm -rf --one-file-system "$GITHUB_WORKSPACE"/* "$GITHUB_WORKSPACE"/.* 2>/dev/null || true
#
#      - name: Checkout code
#        uses: actions/checkout@v4
#        with:
#          clean: true
#
#      - name: Start CI container
#        run: bash scripts/npu_ci_a3_start_container.sh
#
#      - name: Run test
#        timeout-minutes: 30
#        env:
#          SGLANG_USE_MODELSCOPE: true
#          SGLANG_IS_IN_CI: true
#          HF_ENDPOINT: https://hf-mirror.com
#        run: |
#          bash scripts/npu_ci_exec.sh python3 $GITHUB_WORKSPACE/test/srt/test_ascend_disaggregation_deepep.py
#
#      - name: Stop and remove container
#        if: always()
#        run: bash scripts/npu_ci_a3_stop_container.sh

  pr-test-npu-finish:
    if: always()
    needs:
      - per-commit-1-ascend-npu
      - per-commit-2-ascend-npu
      # TODO: recover the deepep tests when A3 multi-node cluster is ready
      #- per-commit-ascend-npu-deepep
    runs-on: ubuntu-latest
    steps:
      - name: Check all dependent job statuses
        run: |
          results=(${{ join(needs.*.result, ' ') }})
          for result in "${results[@]}"; do
            if [ "$result" = "failure" ] || [ "$result" = "cancelled" ]; then
              echo "Job failed with result: $result"
              exit 1
            fi
          done
          echo "All jobs completed successfully"
          exit 0
